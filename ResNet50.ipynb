{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNDlaAt77IwiIWzEITNkwim",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimjaehwankimjaehwan/python_/blob/main/ResNet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. ResNet50 모델 로드:\n",
        "\n",
        "ResNet50 모델은 사전 학습된 가중치(weights='imagenet')로 로드됩니다. 이 모델은 ImageNet 데이터셋에서 학습된 모델로, 1000개의 클래스를 예측할 수 있습니다.\n",
        "\n",
        "2. 이미지 로드:\n",
        "\n",
        "sklearn에서 제공하는 샘플 이미지를 사용합니다. load_sample_image('china.jpg') 또는 load_sample_image('flower.jpg')로 이미지를 로드할 수 있습니다.\n",
        "\n",
        "3. 이미지 전처리:\n",
        "\n",
        "이미지를 ResNet50 모델에 맞는 입력 크기인 224x224로 조정합니다. 이때 이미지 배열을 numpy.resize를 사용해 조정합니다.\n",
        "전처리 함수 preprocess_input을 사용하여 이미지 데이터를 ResNet50이 기대하는 형식으로 변환합니다. 이 함수는 픽셀 값을 적절한 범위로 조정합니다.\n",
        "\n",
        "4. 예측 수행:\n",
        "\n",
        "model.predict(image)를 사용하여 예측을 수행합니다. 이 모델은 입력된 이미지에 대한 예측 확률을 반환합니다.\n",
        "\n",
        "5. 예측 결과 디코딩:\n",
        "\n",
        "decode_predictions를 사용하여 예측 결과를 해석 가능한 레이블로 디코딩합니다. top=3을 사용하여 가장 가능성이 높은 3개의 클래스를 출력합니다.\n",
        "\n",
        "6. 결과 출력:\n",
        "\n",
        "각 예측 결과에 대해 레이블과 해당 확률을 출력합니다."
      ],
      "metadata": {
        "id": "Z01JR6GSYm3d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtXK7PoBYa_V",
        "outputId": "5f36b76a-53aa-421b-9b25-839e9b76c44d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "\u001b[1m102967424/102967424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "\u001b[1m35363/35363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Predicted: [('n04152593', 'screen', 0.10869243), ('n02840245', 'binder', 0.104571015), ('n06359193', 'web_site', 0.049777426)]\n",
            "1: screen (0.11)\n",
            "2: binder (0.10)\n",
            "3: web_site (0.05)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_sample_image\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "\n",
        "# 1. ResNet50 모델 로드\n",
        "model = ResNet50(weights='imagenet')\n",
        "\n",
        "# 2. sklearn에서 제공하는 샘플 이미지 로드\n",
        "# 사용 가능한 샘플 이미지: 'china.jpg', 'flower.jpg'\n",
        "image = load_sample_image('china.jpg')  # 또는 'flower.jpg'\n",
        "image = img_to_array(image)\n",
        "\n",
        "# 3. 이미지 전처리\n",
        "# ResNet50 모델에 입력할 수 있도록 이미지 크기를 224x224로 조정하고, 전처리\n",
        "image = np.resize(image, (224, 224, 3))\n",
        "image = np.expand_dims(image, axis=0)\n",
        "image = preprocess_input(image)\n",
        "\n",
        "# 4. 예측 수행\n",
        "predictions = model.predict(image)\n",
        "\n",
        "# 5. 예측 결과 디코딩 및 출력\n",
        "decoded_predictions = decode_predictions(predictions, top=3)[0]\n",
        "print(\"Predicted:\", decoded_predictions)\n",
        "\n",
        "# 출력된 결과를 해석\n",
        "for i, (imagenet_id, label, score) in enumerate(decoded_predictions):\n",
        "    print(f\"{i+1}: {label} ({score:.2f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* screen (0.11):\n",
        "\n",
        "  모델이 이미지에서 \"스크린(screen)\"이라고 예측한 확률이 약 11%입니다.\n",
        "이 예측이 가장 높은 확률로, 모델은 이미지가 스크린과 관련이 있을 가능성이 있다고 판단했습니다.\n",
        "\n",
        "* binder (0.10):\n",
        "\n",
        "  모델은 또한 이미지가 \"바인더(binder)\"일 가능성을 약 10%로 예측했습니다.\n",
        "이는 바인더(서류철)와 관련된 물체를 인식한 것으로 보입니다.\n",
        "\n",
        "* web_site (0.05):\n",
        "\n",
        "  세 번째로, 모델은 이미지가 \"웹 사이트(web site)\"와 관련이 있을 가능성을 약 5%로 예측했습니다.\n",
        "  이 결과는 이미지에 웹 페이지와 관련된 요소가 있을 수 있다고 인식한 결과입니다."
      ],
      "metadata": {
        "id": "g7-px2CWY89U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_sample_image\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img, ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# 1. ResNet50 모델 로드 및 미세 조정 설정\n",
        "base_model = ResNet50(weights='imagenet', include_top=False)  # 최상위 레이어 제거\n",
        "\n",
        "# 2. 레이어 추가 및 모델 확장\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)  # 드롭아웃 추가\n",
        "predictions = Dense(1000, activation='softmax')(x)  # ImageNet 데이터셋의 클래스 수\n",
        "\n",
        "# 새 모델 정의\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# 3. 사전 학습된 레이어 동결\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False  # ResNet50의 기존 레이어는 학습되지 않도록 동결\n",
        "\n",
        "# 4. 모델 컴파일\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 5. 데이터 증강 설정\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# 6. 샘플 이미지 로드 및 전처리\n",
        "image = load_sample_image('china.jpg')  # 예제 이미지\n",
        "image = img_to_array(image)\n",
        "image = np.resize(image, (224, 224, 3))  # ResNet50 입력 크기에 맞추기\n",
        "image = np.expand_dims(image, axis=0)\n",
        "image = preprocess_input(image)\n",
        "\n",
        "# 7. 예측 수행\n",
        "y_pred = model.predict(image)\n",
        "\n",
        "# 8. 예측 결과 디코딩 및 출력\n",
        "decoded_predictions = decode_predictions(y_pred, top=3)[0]\n",
        "print(\"Predicted:\", decoded_predictions)\n",
        "\n",
        "# 9. 모델 학습 (이 부분은 예제에서 생략됩니다)\n",
        "# 일반적으로 대규모 데이터셋을 사용하여 학습을 진행해야 합니다.\n",
        "# datagen.flow(...) 또는 model.fit(...)을 사용하여 데이터 증강된 이미지로 학습 진행 가능\n",
        "\n",
        "# 조기 종료 설정\n",
        "# early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# 실제 데이터로 모델 학습\n",
        "# model.fit(train_data, validation_data=val_data, epochs=50, callbacks=[early_stopping])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyXDC2_YZeSg",
        "outputId": "ee9c0a14-4ac4-4285-eb85-4cde8dad317b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
            "Predicted: [('n02782093', 'balloon', 0.0087746605), ('n03697007', 'lumbermill', 0.00767095), ('n03478589', 'half_track', 0.0074001565)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* balloon (0.0088):\n",
        "모델은 이미지의 일부를 \"balloon\" (풍선)이라고 인식했을 가능성을 약 0.88%로 예측했습니다.\n",
        "* lumbermill (0.0077):\n",
        "모델은 이미지의 일부를 \"lumbermill\" (제재소)라고 인식할 가능성을 약 0.77%로 예측했습니다.\n",
        "* half_track (0.0074):\n",
        "모델은 이미지의 일부를 \"half_track\" (반트랙, 장갑차의 일종)으로 인식할 가능성을 약 0.74%로 예측했습니다."
      ],
      "metadata": {
        "id": "IZHno8BjZ-Gx"
      }
    }
  ]
}